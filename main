# Gerekli kütüphaneleri yükleme
!pip install resampy
!pip install librosa --upgrade

import os
import numpy as np
import librosa
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from google.colab import drive

# Google Drive'ı bağlama
drive.mount('/content/drive')

data_path = '/content/drive/MyDrive/alfabeses2/'

# Veri Çoğaltma Fonksiyonu
def augment_data(audio, sample_rate):
    augmented_data = []
    augmented_data.append(librosa.effects.time_stretch(audio, rate=1.1))
    augmented_data.append(librosa.effects.time_stretch(audio, rate=0.9))
    noise = 0.005 * np.random.randn(len(audio))
    augmented_data.append(audio + noise)
    return augmented_data

# Özellik Çıkarma Fonksiyonu
def extract_features(file_path):
    audio, sample_rate = librosa.load(file_path, sr=None, res_type='kaiser_fast')
    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    return np.mean(mfccs.T, axis=0)

data = []
labels = []

# Veri yükleme ve artırma
for label in os.listdir(data_path):
    label_path = os.path.join(data_path, label)
    if os.path.isdir(label_path):
        for file in os.listdir(label_path):
            if file.endswith(".wav") or file.endswith(".mp3"):
                file_path = os.path.join(label_path, file)
                audio, sample_rate = librosa.load(file_path, sr=None, res_type='kaiser_fast')
                
                # Ana veriyi ekle
                features = extract_features(file_path)
                data.append(features)
                labels.append(label)
                
                # Veri çoğaltma yap ve ekle
                augmented_audios = augment_data(audio, sample_rate)
                for augmented_audio in augmented_audios:
                    mfccs = librosa.feature.mfcc(y=augmented_audio, sr=sample_rate, n_mfcc=40)
                    augmented_features = np.mean(mfccs.T, axis=0)
                    data.append(augmented_features)
                    labels.append(label)

# Numpy Dizisine Dönüştürme
data = np.array(data)
labels = np.array(labels)

# Etiketleri sayısal değerlere dönüştürme
le = LabelEncoder()
labels = le.fit_transform(labels)

# Veriyi eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# Modeli Oluşturma
num_classes = len(np.unique(labels))  # 29 harf çıktısı için
input_shape = (X_train.shape[1],)  # MFCC uzunluğu

model = Sequential([
    Dense(256, input_shape=input_shape, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01))  # 29 sınıf için softmax
])

# Erken durdurma
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Modeli derleme
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Modeli eğitme
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=16,
    validation_data=(X_test, y_test),
    callbacks=[early_stopping]
)

# Test doğruluğunu değerlendirme
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print("Test Doğruluğu:", test_accuracy)

# Eğitim ve doğrulama doğruluğunu grafikle gösterme
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Eğitim ve doğrulama kaybını grafikle gösterme
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Modelinizi kaydetme
model.save('/content/drive/MyDrive/alfabeses2/model.h5')  # Keras modelini kaydedin

# TensorFlow Lite formatına dönüştürme
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Dönüştürülen modeli kaydetme
with open('/content/drive/MyDrive/alfabeses2/model.tflite', 'wb') as f:
    f.write(tflite_model)

# Etiketleri kaydetme
labels = le.classes_  # Kullanılan etiketleri alın
with open('/content/drive/MyDrive/alfabeses2/labels.txt', 'w') as f:
    for label in labels:
        f.write(f"{label}\n")
